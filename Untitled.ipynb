{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491faa8e-e7e6-4b11-927f-1bba27dab3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "35353e3e-610f-4655-abbe-13091d7f4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= None\n",
    "with open(\"gora_dataset.txt\",\"r\",encoding=\"utf8\") as f:\n",
    "    a = f.read()\n",
    "a = a.replace(\"\\n\\n\",\"\\n\")\n",
    "a = a.replace(\"\\n \\n\",\"\\n\")\n",
    "a = a.replace(\"\\u200c\",\"\")\n",
    "vocab = sorted(list(set(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb0b453e-9e48-48e4-a77d-a43092605c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', 'T', 'a', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'r', 's', 't', 'u', 'v', 'w', 'y', '|', '।', 'ঁ', 'ং', 'ঃ', 'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ', 'ষ', 'স', 'হ', 'া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ে', 'ৈ', 'ো', 'ৌ', '্', 'ৎ', 'ড়', 'ঢ়', 'য়', '৭', '৮', '৻']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e254d259-75b5-4f0a-a1d2-9356d5196228",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_to_ids = {val:key for key,val in enumerate(vocab)}\n",
    "ids_to_tokens = {key:val for key,val in enumerate(vocab)}\n",
    "\n",
    "encode = lambda s: [tokens_to_ids[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([ids_to_tokens[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fe62a702-ef01-42c0-85f0-6e910a195fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, ':': 10, ';': 11, '?': 12, 'T': 13, 'a': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'k': 23, 'l': 24, 'm': 25, 'n': 26, 'o': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'y': 34, '|': 35, '।': 36, 'ঁ': 37, 'ং': 38, 'ঃ': 39, 'অ': 40, 'আ': 41, 'ই': 42, 'ঈ': 43, 'উ': 44, 'ঊ': 45, 'ঋ': 46, 'এ': 47, 'ঐ': 48, 'ও': 49, 'ঔ': 50, 'ক': 51, 'খ': 52, 'গ': 53, 'ঘ': 54, 'ঙ': 55, 'চ': 56, 'ছ': 57, 'জ': 58, 'ঝ': 59, 'ঞ': 60, 'ট': 61, 'ঠ': 62, 'ড': 63, 'ঢ': 64, 'ণ': 65, 'ত': 66, 'থ': 67, 'দ': 68, 'ধ': 69, 'ন': 70, 'প': 71, 'ফ': 72, 'ব': 73, 'ভ': 74, 'ম': 75, 'য': 76, 'র': 77, 'ল': 78, 'শ': 79, 'ষ': 80, 'স': 81, 'হ': 82, 'া': 83, 'ি': 84, 'ী': 85, 'ু': 86, 'ূ': 87, 'ৃ': 88, 'ে': 89, 'ৈ': 90, 'ো': 91, 'ৌ': 92, '্': 93, 'ৎ': 94, 'ড়': 95, 'ঢ়': 96, 'য়': 97, '৭': 98, '৮': 99, '৻': 100}\n"
     ]
    }
   ],
   "source": [
    "print(tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5820e82-9edb-41fc-ac37-df29fb0264e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train - Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "35503ff2-fe80-4367-ae9e-77917f698171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721731, 80193)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [tokens_to_ids[char] for char in a]\n",
    "ids = torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "train_split = int(0.9 * len(ids))\n",
    "train_data = ids[:train_split] \n",
    "val_data = ids[train_split:]\n",
    "len(train_data),len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a5b7f12e-6f6b-4139-82c3-8ef160811f24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([79, 93, 77,  ..., 42, 36,  3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0b8fd0c7-5ffe-4fbb-97ce-eb8ce2162475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape torch.Size([32, 32])\n",
      "y.shape torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "context_length = 17\n",
    "def get_batch(split=\"train\"):\n",
    "    data = train_data if split==\"train\" else val_data\n",
    "    idx = torch.randint(len(data)-batch_size,(batch_size,))\n",
    "    # print(idx)\n",
    "    x = torch.stack([data[i:i+batch_size] for i in idx])\n",
    "    y = torch.stack([data[i+1:i+batch_size+1] for i in idx])\n",
    "    return x,y\n",
    "\n",
    "x,y = get_batch()\n",
    "print(\"x.shape\",x.shape)\n",
    "print(\"y.shape\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ded8db34-9640-4f96-8195-83075c814f44",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[68, 84,  1, 73, 83,  1, 51, 84],\n",
       "        [81, 51, 78, 89, 42,  1, 54, 86],\n",
       "        [70,  1, 41, 71, 70, 83, 77,  1],\n",
       "        [ 1, 66, 52, 70,  1, 73, 77, 93],\n",
       "        [51, 89,  1, 73, 78, 57, 89, 70],\n",
       "        [77, 84, 97, 83, 42,  1, 73, 84],\n",
       "        [68, 84, 70, 51, 83, 77,  1, 41],\n",
       "        [77, 86, 77,  1, 53, 83, 95, 84]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "69f4098d-e824-4fb1-98b2-732260a4cb44",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[84,  1, 73, 83,  1, 51, 84, 57],\n",
       "        [51, 78, 89, 42,  1, 54, 86, 75],\n",
       "        [ 1, 41, 71, 70, 83, 77,  1, 47],\n",
       "        [66, 52, 70,  1, 73, 77, 93, 80],\n",
       "        [89,  1, 73, 78, 57, 89, 70,  1],\n",
       "        [84, 97, 83, 42,  1, 73, 84, 70],\n",
       "        [84, 70, 51, 83, 77,  1, 41, 78],\n",
       "        [86, 77,  1, 53, 83, 95, 84, 66]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6cd08dad-5c1e-4eef-92bb-48673d1aeaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is শ the target: ্\n",
      "when input is শ্ the target: র\n",
      "when input is শ্র the target: া\n",
      "when input is শ্রা the target: ব\n",
      "when input is শ্রাব the target: ণ\n",
      "when input is শ্রাবণ the target:  \n",
      "when input is শ্রাবণ  the target: ম\n",
      "when input is শ্রাবণ ম the target: া\n",
      "when input is শ্রাবণ মা the target: স\n",
      "when input is শ্রাবণ মাস the target: ে\n",
      "when input is শ্রাবণ মাসে the target: র\n",
      "when input is শ্রাবণ মাসের the target:  \n",
      "when input is শ্রাবণ মাসের  the target: স\n",
      "when input is শ্রাবণ মাসের স the target: ক\n",
      "when input is শ্রাবণ মাসের সক the target: া\n",
      "when input is শ্রাবণ মাসের সকা the target: ল\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_lngth]\n",
    "y = train_data[1:context_lngth+1]\n",
    "for t in range(context_lngth):\n",
    "    context = x[:t+1]\n",
    "    target = y[t:t+1]\n",
    "    print(f\"when input is {decode(context.tolist())} the target: {decode(target.tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "29017014-9c95-4676-bcfe-ecd7a267fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "class BigramModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        vocab_size = len(vocab)\n",
    "        self.token_embedding_table = torch.nn.Embedding(vocab_size,vocab_size)\n",
    "    \n",
    "    def forward(self,idx,targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "        return logits,loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        logits1 = self.token_embedding_table(idx)\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            # print(logits.shape)\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            print(\"idx: \",idx,\"idx_next: \",idx_next,\"probs.shape: \",probs.shape,\"\\nlogits.shape:\",logits.shape)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx,logits1\n",
    "    \n",
    "model = BigramModel()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "347eeabc-69a0-4f3e-8e6f-a189f186cf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  tensor([[0]]) idx_next:  tensor([[13]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13]]) idx_next:  tensor([[8]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8]]) idx_next:  tensor([[87]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87]]) idx_next:  tensor([[57]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57]]) idx_next:  tensor([[60]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60]]) idx_next:  tensor([[51]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51]]) idx_next:  tensor([[12]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12]]) idx_next:  tensor([[56]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56]]) idx_next:  tensor([[39]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39]]) idx_next:  tensor([[19]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19]]) idx_next:  tensor([[61]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19, 61]]) idx_next:  tensor([[74]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19, 61, 74]]) idx_next:  tensor([[57]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19, 61, 74, 57]]) idx_next:  tensor([[64]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19, 61, 74, 57, 64]]) idx_next:  tensor([[40]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19, 61, 74, 57, 64, 40]]) idx_next:  tensor([[95]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19, 61, 74, 57, 64, 40, 95]]) idx_next:  tensor([[36]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19, 61, 74, 57, 64, 40, 95, 36]]) idx_next:  tensor([[4]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19, 61, 74, 57, 64, 40, 95, 36,\n",
      "          4]]) idx_next:  tensor([[72]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n",
      "idx:  tensor([[ 0, 13,  8, 87, 57, 60, 51, 12, 56, 39, 19, 61, 74, 57, 64, 40, 95, 36,\n",
      "          4, 72]]) idx_next:  tensor([[52]]) probs.shape:  torch.Size([1, 101]) \n",
      "logits.shape: torch.Size([1, 101])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nT-ূছঞক?চঃgটভছঢঅড়।'ফখ\""
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_test = torch.tensor([[0],[0]],dtype=torch.long)\n",
    "x_test = torch.zeros((1,1),dtype=torch.long)\n",
    "res,log1 = model.generate(x_test,20)\n",
    "decode(res[0].tolist())\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0645fded-d762-4ce5-8d92-95eb81553385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 101])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(model.parameters())\n",
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3cdde907-4eeb-4a65-9735-63c2fda37da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9d630b67-284e-4653-a19b-3532b75e280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1924567222595215\n",
      "5.030435562133789\n",
      "4.872669696807861\n",
      "4.737040996551514\n",
      "4.570051193237305\n",
      "4.444697380065918\n",
      "4.331822872161865\n",
      "4.19584321975708\n",
      "4.090090274810791\n",
      "3.9809329509735107\n",
      "3.8659281730651855\n",
      "3.7684459686279297\n",
      "3.6472818851470947\n",
      "3.588207483291626\n",
      "3.5093092918395996\n",
      "3.400611162185669\n",
      "3.3533196449279785\n",
      "3.259134292602539\n",
      "3.217833995819092\n",
      "3.165424108505249\n",
      "3.1034839153289795\n",
      "3.0291285514831543\n",
      "3.0205492973327637\n",
      "2.9375\n",
      "2.9111363887786865\n",
      "2.8679239749908447\n",
      "2.833810806274414\n",
      "2.8263869285583496\n",
      "2.7596096992492676\n",
      "2.7733166217803955\n",
      "2.7243123054504395\n",
      "2.723829746246338\n",
      "2.709822654724121\n",
      "2.7181882858276367\n",
      "2.636099100112915\n",
      "2.6491129398345947\n",
      "2.605893850326538\n",
      "2.610313653945923\n",
      "2.598336696624756\n",
      "2.599942207336426\n",
      "2.5603623390197754\n",
      "2.574723482131958\n",
      "2.562505006790161\n",
      "2.57490611076355\n",
      "2.5329720973968506\n",
      "2.5175657272338867\n",
      "2.5226662158966064\n",
      "2.5016257762908936\n",
      "2.5323903560638428\n",
      "2.500088691711426\n",
      "2.4719085693359375\n",
      "2.515918016433716\n",
      "2.4839954376220703\n",
      "2.5055668354034424\n",
      "2.5148961544036865\n",
      "2.492889165878296\n",
      "2.490314483642578\n",
      "2.517550230026245\n",
      "2.460301637649536\n",
      "2.4688806533813477\n",
      "2.4796018600463867\n",
      "2.497328042984009\n",
      "2.463029384613037\n",
      "2.4761128425598145\n",
      "2.4714581966400146\n",
      "2.4553749561309814\n",
      "2.5001485347747803\n",
      "2.4645004272460938\n",
      "2.48203706741333\n",
      "2.4834518432617188\n",
      "2.458436965942383\n",
      "2.4110286235809326\n",
      "2.4417738914489746\n",
      "2.492044448852539\n",
      "2.4762165546417236\n",
      "2.4688913822174072\n",
      "2.4681689739227295\n",
      "2.4671225547790527\n",
      "2.44840931892395\n",
      "2.458158016204834\n",
      "2.436830997467041\n",
      "2.4839870929718018\n",
      "2.4747700691223145\n",
      "2.465804100036621\n",
      "2.4888980388641357\n",
      "2.4908058643341064\n",
      "2.4637107849121094\n",
      "2.477189779281616\n",
      "2.413804769515991\n",
      "2.4445624351501465\n",
      "2.499720811843872\n",
      "2.4482603073120117\n",
      "2.416796922683716\n",
      "2.477480888366699\n",
      "2.472323179244995\n",
      "2.444857120513916\n",
      "2.4582207202911377\n",
      "2.429715156555176\n",
      "2.431382894515991\n",
      "2.499154806137085\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "    x,y = get_batch()\n",
    "    logits,loss = model(x,y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step%100==0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a03f35c3-93b1-448b-b393-3cba924f413d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nএখাছ শেরাড়ালি \"আনে নবৈর পমনেইহার \"\\nবিঁপা, সক ক্ষ্ধাইবে কহাতিসকঠিলোনেরেদিম?\"\\nএই যখবং পকথাও পারাহার ভাক্ধেখন রনেটা দে তকী \"সংর বে সে আসি ইলাকা স্গতেটা তে তায়ে সংকোক্যকিতাগো গের কেরব মাতিয়াজনতাতন জনিয়েল '"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = torch.tensor([[0],[0]],dtype=torch.long)\n",
    "res,log1 = model.generate(x_test,200)\n",
    "decode(res[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "063bdf3f-ffe3-4260-b607-f891e6087cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 21])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba1062-6794-4af2-aeb0-52969a4d7b12",
   "metadata": {},
   "source": [
    "## With Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "3f71ab5c-e6d9-4ff6-a9cc-e4a708071821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "class OptimusBeta(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vocab_size = len(vocab)\n",
    "        self.embed_len = 128\n",
    "        self.head_size = 128\n",
    "        self.token_embedding_table = torch.nn.Embedding(self.vocab_size,self.embed_len)\n",
    "        self.key = nn.Linear(self.embed_len,self.head_size,bias=False)\n",
    "        self.query = nn.Linear(self.embed_len,self.head_size,bias=False)\n",
    "        self.val = nn.Linear(self.embed_len,self.head_size,bias=False)\n",
    "        self.lm_head1 = nn.Linear(self.head_size,256)\n",
    "        self.lm_head2 = nn.Linear(256,self.vocab_size)\n",
    "        \n",
    "    def forward(self,idx,targets=None):\n",
    "        x = self.token_embedding_table(idx) # (B, T, embed_len)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B, T, head_size)\n",
    "        q = self.query(x) # (B, T, head_size)\n",
    "        v = self.val(x)   # (B, T, head_size)\n",
    "        attention_matrix = k @ q.transpose(-2,-1) * C**-0.5 #  (B, T, head_size) X ( B, head_size, T) = (B, T, T)\n",
    "        tril = torch.tril(torch.ones(T,T))\n",
    "        attention_matrix = attention_matrix.masked_fill(tril == 0, float('-inf')) # (B, T, T)\n",
    "        attention_matrix = F.softmax(attention_matrix, dim=-1) # (B, T, T) -> \n",
    "        # print(\"attention_matrix.shape: \",attention_matrix.shape, \"v.shape: \",v.shape)\n",
    "        \n",
    "        out_logits = attention_matrix @ v # (B, T, T) X (B, T, head_size) = (B, T, head_size)\n",
    "        \n",
    "        \n",
    "        # print(\"------------>\")\n",
    "        # print(\"x.shape\",x.shape,\"\\nk.shape: \",k.shape,\"\\nattention_mask.shape: \",attention_matrix.shape,\"\\nout_logits.shape: \",out_logits.shape,\"\\ntargets.shape: \",targets)\n",
    "        # print(\"B,T,C: \",B,T,C)\n",
    "        # print(\"<------------\")\n",
    "        out_logits = self.lm_head1(out_logits)\n",
    "        out_logits = self.lm_head2(out_logits)\n",
    "        out_logits2 = out_logits.view(B*T,self.vocab_size)\n",
    "        \n",
    "        \n",
    "        if targets is None: # target -> (B, T)\n",
    "            loss = None\n",
    "        else:\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(out_logits2,targets)\n",
    "        return out_logits,loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        logits1 = self.token_embedding_table(idx)\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx) # (B, T, embed_len)\n",
    "            # focus only on the last time step\n",
    "            # print(\"logits shape -> \",logits.shape)\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # idx_next = torch.argmax(probs).view(1,1)\n",
    "            # print(\"idx\",idx,\"idx_next\",idx_next,\"probs.shape\",probs.shape,\"\\nlogits.shape:\",logits.shape)\n",
    "            # append sampled index to the running sequence\n",
    "            # print(\"probs: \",probs, \"\\nidx_next: \",idx_next)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx,logits1,probs\n",
    "    \n",
    "model = OptimusBeta()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=1e-3)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "5593d748-e852-4584-a00e-cb2c783da4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nঊম'"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = torch.zeros((1, 1), dtype=torch.long)\n",
    "# x_test = torch.tensor([[0],[0]],dtype=torch.long)\n",
    "res,log1,probs = model.generate(x_test,2)\n",
    "decode(res[0].tolist())\n",
    "# idx:  tensor([[0]]) idx_next:  tensor([[13]]) probs.shape:  torch.Size([1, 101]) \n",
    "# logits.shape: torch.Size([1, 101])\n",
    "\n",
    "# idx:  tensor([[ 0, 13]]) idx_next:  tensor([[8]]) probs.shape:  torch.Size([1, 101]) \n",
    "# logits.shape: torch.Size([1, 101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d77b2d-ec29-4195-a8d5-130da4ab1563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0 loss:  4.624670028686523\n",
      "step:  200 loss:  2.697680711746216\n",
      "step:  400 loss:  2.5540690422058105\n",
      "step:  600 loss:  2.4962475299835205\n",
      "step:  800 loss:  2.514400005340576\n",
      "step:  1000 loss:  2.4994544982910156\n",
      "step:  1200 loss:  2.4298484325408936\n",
      "step:  1400 loss:  2.444282293319702\n",
      "step:  1600 loss:  2.4806244373321533\n",
      "step:  1800 loss:  2.467045545578003\n",
      "step:  2000 loss:  2.462272882461548\n",
      "step:  2200 loss:  2.4769208431243896\n",
      "step:  2400 loss:  2.4996180534362793\n",
      "step:  2600 loss:  2.47139310836792\n",
      "step:  2800 loss:  2.4554412364959717\n",
      "step:  3000 loss:  2.455787181854248\n",
      "step:  3200 loss:  2.4618654251098633\n",
      "step:  3400 loss:  2.3340179920196533\n",
      "step:  3600 loss:  2.3889763355255127\n",
      "step:  3800 loss:  2.461803913116455\n",
      "step:  4000 loss:  2.38619065284729\n",
      "step:  4200 loss:  2.4255905151367188\n",
      "step:  4400 loss:  2.4297943115234375\n",
      "step:  4600 loss:  2.4593119621276855\n",
      "step:  4800 loss:  2.38258957862854\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "    x,y = get_batch()\n",
    "    logits,loss = model(x,y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step%200==0:\n",
    "        print(\"step: \",step,\"loss: \",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "7b195584-48c6-4c91-80c0-92e916f5c19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ar\\nসেয়া ফিল, দেতুমনহিনাক্লিয়াহচারের নাহইতাহিবা শা আপিয়াছ এই তাদো মারদ্যখুররাৎসিত্র পু পত- গে অস্তা আধ'"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = torch.tensor([[14]],dtype=torch.long)\n",
    "res,log1,_ = model.generate(x_test,100)\n",
    "decode(res[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "ed97b27c-15e1-4cd3-8b2b-e88690a2b3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.tensor([[0,3,0.2,0.1,0.4]])\n",
    "torch.multinomial(probs, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "96632514-4a28-4570-895b-2600d3117820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad99e3c-ce04-42e1-89bc-42ed480e074a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
